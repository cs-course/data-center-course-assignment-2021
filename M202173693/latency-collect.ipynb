{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from boto3.session import Session\n",
    "import botocore\n",
    "from tqdm import tqdm\n",
    "import throttle\n",
    "import numpy as np\n",
    "\n",
    "# 准备密钥\n",
    "aws_access_key_id = 'hust'\n",
    "aws_secret_access_key = 'hust_obs'\n",
    "\n",
    "# 本地S3服务地址\n",
    "local_s3 = 'http://192.168.75.135:9000'\n",
    "\n",
    "# 建立会话\n",
    "session = Session(aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key)\n",
    "\n",
    "# 连接到服务\n",
    "s3 = session.resource('s3', endpoint_url=local_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucket name:bucket1\n"
     ]
    }
   ],
   "source": [
    "for bucket in s3.buckets.all():\n",
    "    print('bucket name:%s' % bucket.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'test100objs'\n",
    "if s3.Bucket(bucket_name) not in s3.buckets.all():\n",
    "    s3.create_bucket(Bucket=bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = s3.Bucket(bucket_name)\n",
    "for obj in bucket.objects.all():\n",
    "    print('obj name:%s' % obj.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化本地数据文件\n",
    "local_file = \"_test_4K.bin\"\n",
    "test_bytes = [0xFF for i in range(1024*4)] # 填充至所需大小\n",
    "\n",
    "with open(local_file, \"wb\") as lf:\n",
    "    lf.write(bytearray(test_bytes))\n",
    "\n",
    "# 发起请求和计算系统停留时间\n",
    "def request_timing(s3res, i): # 使用独立 session.resource 以保证线程安全\n",
    "    obj_name = \"testObj%08d\"%(i,) # 所建对象名\n",
    "    # temp_file = '.tempfile'\n",
    "    service_time = 0 # 系统滞留时间\n",
    "    start = time.time()\n",
    "    s3res.Object(bucket_name, obj_name).upload_file(local_file) # 将本地文件上传为对象\n",
    "    # 或\n",
    "    # bucket.put_object(Key=obj_name, Body=open(local_file, 'rb'))\n",
    "    # 下载obj\n",
    "    # s3res.Object(bucket_name, obj_name).download_file(temp_file)\n",
    "    end = time.time()\n",
    "    system_time = end - start\n",
    "    return system_time * 1000 # 换算为毫秒\n",
    "\n",
    "# 按照请求到达率限制来执行和跟踪请求\n",
    "def arrival_rate_max(s3res, i): # 不进行限速\n",
    "    return request_timing(s3res, i)\n",
    "\n",
    "@throttle.wrap(0.1, 2) # 100ms 内不超过 2 个请求，下同……\n",
    "def arrival_rate_2(s3res, i):\n",
    "    return request_timing(s3res, i)\n",
    "\n",
    "@throttle.wrap(0.1, 4)\n",
    "def arrival_rate_4(s3res, i):\n",
    "    return request_timing(s3res, i)\n",
    "\n",
    "@throttle.wrap(0.1, 8)\n",
    "def arrival_rate_8(s3res, i):\n",
    "    return request_timing(s3res, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accessing S3: 100%|██████████| 100/100 [00:02<00:00, 38.60it/s]\n"
     ]
    }
   ],
   "source": [
    "latency = []\n",
    "failed_requests = []\n",
    "futures = []\n",
    "with tqdm(desc=\"Accessing S3\", total=100) as pbar:      # 进度条设置，合计执行 100 项上传任务 (见 submit 部分)，进度也设置为 100 步\n",
    "    with ThreadPoolExecutor(max_workers=1) as executor: # 通过 max_workers 设置并发线程数\n",
    "        futures = [\n",
    "            executor.submit(\n",
    "                arrival_rate_max,\n",
    "                session.resource('s3', endpoint_url=local_s3), i) for i in range(100) # 为保证线程安全，应给每个任务申请一个新 resource\n",
    "        ]\n",
    "        for future in as_completed(futures):\n",
    "            if future.exception():\n",
    "                failed_requests.append(futures[future])\n",
    "            else:\n",
    "                latency.append(future.result()) # 正确完成的请求，采集延迟\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"latency.csv\", \"w+\") as tracefile:\n",
    "    tracefile.write(\"latency\\n\")\n",
    "    tracefile.writelines([str(l) + '\\n' for l in latency])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accessing S3: 100%|██████████| 9/9 [00:00<00:00, 45.38it/s]\n"
     ]
    }
   ],
   "source": [
    "value = 50\n",
    "ddl_latency_num = sum(x>value for x in latency)\n",
    "latency_hedged = [x for x in latency if x<=value]\n",
    "with tqdm(desc=\"Accessing S3\", total=ddl_latency_num) as pbar:      # 进度条设置，合计执行 100 项上传任务 (见 submit 部分)，进度也设置为 100 步\n",
    "    with ThreadPoolExecutor(max_workers=1) as executor: # 通过 max_workers 设置并发线程数\n",
    "        futures1 = [\n",
    "            executor.submit(\n",
    "                arrival_rate_max,\n",
    "                session.resource('s3', endpoint_url=local_s3), i) for i in range(ddl_latency_num) # 为保证线程安全，应给每个任务申请一个新 resource\n",
    "        ]\n",
    "        for future1 in as_completed(futures1):\n",
    "            if future1.exception():\n",
    "                failed_requests.append(futures1[future1])\n",
    "            else:\n",
    "                latency_hedged.append(future1.result()) # 正确完成的请求，采集延迟\n",
    "            pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # 删除bucket下所有object\n",
    "    bucket.objects.filter().delete()\n",
    "\n",
    "    # 删除bucket下某个object\n",
    "    # bucket.objects.filter(Prefix=obj_name).delete()\n",
    "\n",
    "    bucket.delete()\n",
    "except botocore.exceptions.ClientError as e:\n",
    "    print('error in bucket removal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(local_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"latency_hedged.csv\", \"w+\") as tracefile:\n",
    "    tracefile.write(\"latency\\n\")\n",
    "    tracefile.writelines([str(l) + '\\n' for l in latency_hedged])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
